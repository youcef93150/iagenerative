"""
Moteur NLP SÃ©mantique (SBERT)
EF2 : Moteur NLP SÃ©mantique (CÅ“ur du Projet - CoÃ»t ZÃ©ro)

ImplÃ©mente l'analyse sÃ©mantique basÃ©e sur les embeddings contextuels SBERT
et le calcul de similaritÃ© cosinus.

Architecture inspirÃ©e d'AISCA appliquÃ©e au cinÃ©ma.
"""

import pandas as pd
import numpy as np
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity
from typing import List, Dict, Tuple, Optional
import logging

logger = logging.getLogger(__name__)


class NLPEngine:
    """
    Moteur d'analyse sÃ©mantique utilisant SBERT (EF2)
    
    Ã‰quivalent au moteur de matching de compÃ©tences d'AISCA,
    adaptÃ© pour la recommandation de films.
    """
    
    def __init__(self, model_name: str = 'paraphrase-multilingual-MiniLM-L12-v2'):
        """
        Initialise le moteur NLP avec SBERT (EF2.2)
        
        Args:
            model_name: Nom du modÃ¨le SentenceTransformer
                       (multilingue pour supporter le franÃ§ais)
        """
        logger.info(f"ðŸ”„ Chargement du modÃ¨le SBERT: {model_name}")
        
        # EF2.2: ModÃ©lisation SÃ©mantique avec SBERT (Open-Source, Local, CoÃ»t ZÃ©ro)
        self.model = SentenceTransformer(model_name)
        self.model_name = model_name
        self.referentiel = None
        self.embeddings_cache = {}
        
        logger.info("âœ… ModÃ¨le SBERT chargÃ© avec succÃ¨s")
    
    def load_referentiel(self, filepath: str = 'data/films_referentiel.csv') -> pd.DataFrame:
        """
        Charge le rÃ©fÃ©rentiel de films (EF2.1 - RÃ©fÃ©rentiel de CompÃ©tences adaptÃ©)
        
        Dans AISCA: charge les blocs de compÃ©tences
        Ici: charge les blocs de genres cinÃ©matographiques
        
        Args:
            filepath: Chemin vers le fichier CSV du rÃ©fÃ©rentiel
            
        Returns:
            DataFrame du rÃ©fÃ©rentiel
        """
        logger.info(f"ðŸ“‚ Chargement du rÃ©fÃ©rentiel cinÃ©matographique: {filepath}")
        
        self.referentiel = pd.read_csv(filepath)
        
        # CrÃ©er une colonne avec la description complÃ¨te pour l'analyse sÃ©mantique
        # (Ã©quivalent Ã  la compilation des compÃ©tences dans AISCA)
        self.referentiel['texte_complet'] = self.referentiel.apply(
            lambda row: self._build_film_text(row),
            axis=1
        )
        
        logger.info(f"âœ… RÃ©fÃ©rentiel chargÃ©: {len(self.referentiel)} films rÃ©partis en blocs de genres")
        logger.info(f"ðŸ“Š Genres disponibles: {self.referentiel['Categorie'].unique().tolist()}")
        
        return self.referentiel
    
    def _build_film_text(self, row: pd.Series) -> str:
        """
        Construit le texte sÃ©mantique complet d'un film
        
        Args:
            row: Ligne du DataFrame
            
        Returns:
            Texte enrichi pour l'embedding
        """
        return (
            f"{row['Film']} ({row['Annee']}). "
            f"RÃ©alisÃ© par {row['Realisateur']}. "
            f"Genre: {row['Genre']}. "
            f"Description: {row['Description']} "
            f"Mots-clÃ©s: {row['Keywords']}. "
            f"Ambiance: {row['Mood']}."
        )
    
    def encode_text(self, text: str, cache_key: Optional[str] = None) -> np.ndarray:
        """
        Encode un texte en vecteur d'embeddings (EF2.2 - SBERT)
        
        Args:
            text: Texte Ã  encoder
            cache_key: ClÃ© pour le cache (optionnel)
            
        Returns:
            Vecteur d'embeddings contextuels
        """
        # VÃ©rifier le cache
        if cache_key and cache_key in self.embeddings_cache:
            logger.debug(f"âœ… Cache HIT pour: {cache_key}")
            return self.embeddings_cache[cache_key]
        
        # Encoder le texte avec SBERT
        embedding = self.model.encode(text, convert_to_numpy=True, show_progress_bar=False)
        
        # Mettre en cache
        if cache_key:
            self.embeddings_cache[cache_key] = embedding
            logger.debug(f"ðŸ’¾ Embedding mis en cache: {cache_key}")
        
        return embedding
    
    def encode_referentiel(self) -> np.ndarray:
        """
        Encode tous les films du rÃ©fÃ©rentiel en embeddings
        
        Ã‰quivalent AISCA: encode tous les blocs de compÃ©tences
        
        Returns:
            Matrice d'embeddings (n_films, embedding_dim)
        """
        if self.referentiel is None:
            raise ValueError("âŒ Le rÃ©fÃ©rentiel doit Ãªtre chargÃ© avant l'encodage")
        
        logger.info(f"ðŸ”„ Encodage de {len(self.referentiel)} films avec SBERT...")
        
        # Encoder tous les textes
        embeddings = self.model.encode(
            self.referentiel['texte_complet'].tolist(),
            convert_to_numpy=True,
            show_progress_bar=True,
            batch_size=32
        )
        
        logger.info(f"âœ… Encodage terminÃ© - Shape: {embeddings.shape}")
        
        return embeddings
    
    def calculate_similarity(
        self, 
        user_embedding: np.ndarray, 
        referentiel_embeddings: np.ndarray
    ) -> np.ndarray:
        """
        Calcule la similaritÃ© cosinus (EF2.3 - Mesure de SimilaritÃ©)
        
        Ã‰quivalent AISCA: calcule le matching entre profil utilisateur et compÃ©tences
        
        Args:
            user_embedding: Embedding de la requÃªte utilisateur
            referentiel_embeddings: Embeddings du rÃ©fÃ©rentiel de films
            
        Returns:
            Array des scores de similaritÃ© [0, 1]
        """
        # Reshape si nÃ©cessaire
        if user_embedding.ndim == 1:
            user_embedding = user_embedding.reshape(1, -1)
        
        # EF2.3: Mesure de SimilaritÃ© Cosinus
        similarities = cosine_similarity(user_embedding, referentiel_embeddings)[0]
        
        logger.info(f"ðŸ“Š SimilaritÃ© calculÃ©e - "
                   f"Min: {similarities.min():.3f}, "
                   f"Max: {similarities.max():.3f}, "
                   f"Moyenne: {similarities.mean():.3f}")
        
        return similarities
    
    def get_top_matches(
        self, 
        similarities: np.ndarray, 
        top_n: int = 3
    ) -> List[Tuple[int, float]]:
        """
        RÃ©cupÃ¨re les top N films les plus similaires
        
        Ã‰quivalent AISCA: rÃ©cupÃ¨re les top profils mÃ©tiers
        
        Args:
            similarities: Array des scores de similaritÃ©
            top_n: Nombre de recommandations Ã  retourner (dÃ©faut: 3 comme dans AISCA)
            
        Returns:
            Liste de tuples (index, score) triÃ©e par score dÃ©croissant
        """
        # Trier par similaritÃ© dÃ©croissante
        top_indices = np.argsort(similarities)[::-1][:top_n]
        
        results = [(idx, float(similarities[idx])) for idx in top_indices]
        
        logger.info(f"ðŸŽ¯ Top {top_n} matches identifiÃ©s avec scores: {[f'{s:.3f}' for _, s in results]}")
        
        return results
    
    def analyze_user_input(
        self, 
        user_text: str, 
        top_n: int = 3
    ) -> Tuple[List[Dict], np.ndarray]:
        """
        Pipeline complet d'analyse sÃ©mantique
        
        Ã‰quivalent AISCA: pipeline complet de cartographie des compÃ©tences
        
        Args:
            user_text: Texte consolidÃ© de l'utilisateur
            top_n: Nombre de recommandations (EF3.2: top 3)
            
        Returns:
            (recommandations, similaritÃ©s): Liste des films recommandÃ©s et array des scores
        """
        if self.referentiel is None:
            raise ValueError("âŒ Le rÃ©fÃ©rentiel doit Ãªtre chargÃ© avant l'analyse")
        
        logger.info("ðŸ” DÃ©but de l'analyse sÃ©mantique...")
        
        # 1. Encoder l'entrÃ©e utilisateur
        logger.info("ðŸ“ Ã‰tape 1/4: Encodage de l'entrÃ©e utilisateur")
        user_embedding = self.encode_text(user_text, cache_key="current_user_query")
        
        # 2. Encoder le rÃ©fÃ©rentiel
        logger.info("ðŸ“š Ã‰tape 2/4: Encodage du rÃ©fÃ©rentiel de films")
        referentiel_embeddings = self.encode_referentiel()
        
        # 3. Calculer les similaritÃ©s
        logger.info("ðŸ”¢ Ã‰tape 3/4: Calcul de la similaritÃ© cosinus")
        similarities = self.calculate_similarity(user_embedding, referentiel_embeddings)
        
        # 4. Obtenir les top matches
        logger.info(f"ðŸŽ¯ Ã‰tape 4/4: Extraction des top {top_n} recommandations")
        top_matches = self.get_top_matches(similarities, top_n)
        
        # 5. Construire les recommandations dÃ©taillÃ©es
        recommendations = []
        for idx, score in top_matches:
            film = self.referentiel.iloc[idx]
            recommendations.append({
                'film_id': film['FilmID'],
                'titre': film['Film'],
                'realisateur': film['Realisateur'],
                'annee': int(film['Annee']),
                'genre': film['Genre'],
                'categorie': film['Categorie'],
                'description': film['Description'],
                'keywords': film['Keywords'],
                'mood': film['Mood'],
                'block_id': film['BlockID'],
                'score_similarite': float(score),
                'rang': len(recommendations) + 1
            })
        
        logger.info(f"âœ… Analyse terminÃ©e: {len(recommendations)} recommandations gÃ©nÃ©rÃ©es")
        
        return recommendations, similarities
    
    def get_genre_distribution(
        self, 
        similarities: np.ndarray, 
        threshold: float = 0.5
    ) -> Dict[str, float]:
        """
        Analyse la distribution des genres basÃ©e sur la similaritÃ©
        
        Ã‰quivalent AISCA: distribution des blocs de compÃ©tences
        
        Args:
            similarities: Array des scores de similaritÃ©
            threshold: Seuil minimal de similaritÃ©
            
        Returns:
            Dictionnaire {genre: score_moyen} triÃ© par score dÃ©croissant
        """
        if self.referentiel is None:
            return {}
        
        # Filtrer les films au-dessus du seuil
        mask = similarities >= threshold
        
        if not mask.any():
            logger.warning(f"âš ï¸ Aucun film au-dessus du seuil {threshold}")
            return {}
        
        # Calculer les scores moyens par genre
        genre_scores = {}
        
        for genre in self.referentiel['Categorie'].unique():
            genre_mask = self.referentiel['Categorie'] == genre
            combined_mask = mask & genre_mask
            
            if combined_mask.any():
                genre_scores[genre] = float(similarities[combined_mask].mean())
        
        # Trier par score dÃ©croissant
        sorted_genres = dict(sorted(genre_scores.items(), key=lambda x: x[1], reverse=True))
        
        logger.info(f"ðŸ“Š Distribution des genres (seuil {threshold}): {len(sorted_genres)} genres")
        
        return sorted_genres
    
    def get_coverage_stats(self, similarities: np.ndarray) -> Dict:
        """
        Statistiques de couverture du profil utilisateur
        
        Ã‰quivalent AISCA: couverture des compÃ©tences
        
        Args:
            similarities: Array des scores de similaritÃ©
            
        Returns:
            Statistiques dÃ©taillÃ©es
        """
        return {
            'score_moyen': float(similarities.mean()),
            'score_median': float(np.median(similarities)),
            'score_max': float(similarities.max()),
            'score_min': float(similarities.min()),
            'films_haute_affinite': int((similarities >= 0.7).sum()),
            'films_affinite_moyenne': int(((similarities >= 0.5) & (similarities < 0.7)).sum()),
            'films_faible_affinite': int((similarities < 0.5).sum()),
            'total_films': len(similarities)
        }
